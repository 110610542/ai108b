110610542 資工三 李智傑 AI非監督式學習及應用實例研究報告
    近年來AI人工智慧技術高度蓬勃發展，國際上亦有「OpenAI」等非營利組織針對人工智慧發展各種AI專案，諸如AI鬼抓人、AI破解魔術方塊等等令人歎為觀止的技術。
而在眾多AI技術專案中，較讓我感興趣的有近幾年透過強大計算能力、神經網路及深度學習打敗了韓國九段棋士李世乭、在國際圍棋棋壇大放異彩的「AlphaGo」。AlphaGo
為Google Deepmind的專案。
    首先，圍棋是一種「兩人零和有限完全情報遊戲」——這種遊戲的定義為：參與遊戲者為兩人、遊戲最終的博弈得失總和必為零(勝出為1、敗北為-1、平局為0，而參與玩
家最終總合為0)、遊戲變化數(賽局樹)非無限(圍棋棋局可能變化雖龐大但並非無限)、遊戲其中沒有機率要素混入、場上玩家一切資訊盡數公開，沒有隱藏資訊(若是玩家須
持有手牌的遊戲，手牌即是一種隱藏資訊)。而圍棋屬於這種遊戲，這種遊戲已被證明必定有最佳解法，此類遊戲若參與雙方都以最佳解法下手，則最終必定只有三種情況：
先手必勝出、後手必勝出、雙方必平局，若不符合這種遊戲則絕不會有先後手必勝或必定平局的情況。因此可知道，圍棋雖然變化萬千彷如無限，但始終存在著唯一的最佳解
法。而AlphaGo則是透過蒙地卡羅樹搜尋、生成對抗網路等演算方式，嘗試透過不斷的模擬訓練對奕來尋求出最佳解的人工智慧專案。
    然而，圍棋的可能棋局終究是太過龐大(可能性多達10^360)，因此現今的電腦性能仍無法在有生之年求得最佳解法，否則李世乭也不可能在五局對奕之中仍成功代表人
類擊敗了一次AlphaGo。但人類和AI有著不可跨越的差距，簡單來說，現實世界的人類選手有著腦力和體力的極限，若是下棋與思考時間過長、過度的動腦可能會消耗大量的
體力，使得精神力、專注度與思考能力逐漸下降，並且人類還有著心理素質這一關卡(面對敵手下出絕好的一手、棋局逐漸對己方不利要如何維持平穩心態對抗)。然而AI沒有
體力和精神力方面的限制，總是能以最快及最佳的方式思索棋路，而這就是AI強大之處。除此之外，AI還擁有人類絕不可能效仿的性能，那就是模擬訓練。
    模擬訓練即是所謂的「非監督式學習」，非監督式學習是機器學習的一環。這種方式就如字面上的意思一樣——不受到監督、不事前接收任何的範例與練習並遵從指示。而
是由AI本身對自己進行「訓練」。而AlphaGo即是使用了這種學習方式，在短短幾天內和自己進行了數百萬次的對弈。從起初的只了解圍棋規則而從未實際下棋過，直到透過
無數次和自己對奕取得大量的棋路資訊，將這些資訊彙整起來並從中學習，去摸索更加絕妙的棋路，直到數天後已經達成能夠打敗頂尖人類棋手的等級。這種學習方式絕
不是人類所能效仿，這即是為何AI能夠如此強大的原因，而前面所提到的「OpenAI」組織的一個「AI鬼抓人」專案即是使用了這種生成對抗網路方式訓練。
    至此，不得不讚嘆AI技術在多年發展之下的強大，也可以期待AI今後將會為人類帶來多少正向的改變。如今的AlphaGo恐怕已是沒有人類能夠打敗的水準，但人類選手也
無須為此哀嘆，反而可以順便向AlphaGo學習，或許能夠練習出突破現代棋壇常識的棋路，而使得自己棋力大為增進，這正是AI為人類帶來的正向改變之一呢！
